# Dockerfile.dbx164lts
FROM ubuntu:24.04

ARG DEBIAN_FRONTEND=noninteractive

# System tools
RUN apt-get update && apt-get install -y --no-install-recommends \
      curl \
      wget \
      unzip \
      gnupg2 \
      ca-certificates \
      software-properties-common \
      build-essential \
      git \
      python3.12 \
      python3.12-venv \
      python3.12-dev \
      python3-pip \
      gettext-base \
      mariadb-client \
    && rm -rf /var/lib/apt/lists/*

# Azul Zulu JDK 17.54+21
# RUN curl -s https://repos.azul.com/azul-repo.key | apt-key add - \
#     && echo "deb https://repos.azul.com/zulu/deb stable main" > /etc/apt/sources.list.d/zulu.list \
#     && apt-get update \
#     && apt-get install -y --no-install-recommends zulu17-jdk=17.54+21-1 \
#     && rm -rf /var/lib/apt/lists/*

# ENV JAVA_HOME=/usr/lib/jvm/zulu17 \
#     PATH=$JAVA_HOME/bin:$PATH

# ARG ZULU_BUILD=zulu17.54.21-ca-jdk17.0.13-linux_x64
# RUN curl -fsSL "https://cdn.azul.com/zulu/bin/${ZULU_BUILD}.tar.gz" \
#       | tar -xz -C /opt \
#     && ln -s /opt/zulu*/ /opt/zulu

# ENV JAVA_HOME=/opt/zulu \
#     PATH="$JAVA_HOME/bin:$PATH"

RUN apt-get update \
    && apt-get install -y --no-install-recommends openjdk-17-jdk-headless \
    && rm -rf /var/lib/apt/lists/*

ARG TARGETARCH
RUN arch="${TARGETARCH:-$(dpkg --print-architecture)}" \
    && ln -s "/usr/lib/jvm/java-17-openjdk-${arch}" /usr/lib/jvm/java-17-openjdk || true

ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk
ENV PATH="${JAVA_HOME}/bin:${PATH}"
# ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64 \
#     PATH="$JAVA_HOME/bin:$PATH"

# R 4.4.0
# RUN curl -fsSL https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc \
#       | gpg --dearmor > /usr/share/keyrings/cran-r.gpg \
#     && echo "deb [signed-by=/usr/share/keyrings/cran-r.gpg] https://cloud.r-project.org/bin/linux/ubuntu noble-cran40/" \
#       > /etc/apt/sources.list.d/cran-r.list \
#     && apt-get update \
#     && apt-get install -y --no-install-recommends r-base=4.4.0-* \
#     && rm -rf /var/lib/apt/lists/*

# R
RUN apt-get update \
    && apt-get install -y --no-install-recommends r-base \
    && rm -rf /var/lib/apt/lists/*

# Scala 2.12.20
# Databricks 16.4 LTS uses SCALA_VERSION=2.12.15, but 2.12.20 was requested
ENV SCALA_VERSION=2.12.20
RUN curl -fsSL https://downloads.lightbend.com/scala/${SCALA_VERSION}/scala-${SCALA_VERSION}.tgz \
      | tar -xz -C /usr/local \
    && ln -s /usr/local/scala-${SCALA_VERSION} /usr/local/scala \
    && ln -s /usr/local/scala/bin/* /usr/local/bin/

# Spark 3.5.2 with Hadoop 3 (compatible with DBR 16.4)
ENV SPARK_VERSION=3.5.2 \
    HADOOP_VERSION=3 \
    SPARK_HOME=/opt/spark \
    PATH=/opt/spark/bin:$PATH

RUN curl -fsSL https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz \
      | tar -xz -C /opt \
    && mv /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} ${SPARK_HOME}

# Hadoop Azure
ARG HADOOP_AZURE_VER=3.3.6 \
    AZURE_STORAGE_VER=8.6.6

RUN mkdir -p ${SPARK_HOME}/jars \
    && curl -fsSL https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-azure/${HADOOP_AZURE_VER}/hadoop-azure-${HADOOP_AZURE_VER}.jar \
      -o ${SPARK_HOME}/jars/hadoop-azure-${HADOOP_AZURE_VER}.jar \
    && curl -fsSL https://repo1.maven.org/maven2/com/microsoft/azure/azure-storage/${AZURE_STORAGE_VER}/azure-storage-${AZURE_STORAGE_VER}.jar \
      -o ${SPARK_HOME}/jars/azure-storage-${AZURE_STORAGE_VER}.jar

# Delta Lake 3.3.1
RUN mkdir -p ${SPARK_HOME}/jars \
    && curl -L https://repo1.maven.org/maven2/io/delta/delta-core_2.12/3.3.1/delta-core_2.12-3.3.1.jar \
      -o ${SPARK_HOME}/jars/delta-core_2.12-3.3.1.jar \
    && curl -L https://repo1.maven.org/maven2/io/delta/delta-storage/3.3.1/delta-storage-3.3.1.jar \
      -o ${SPARK_HOME}/jars/delta-storage-3.3.1.jar

# MariaDB JDBC
RUN curl -fsSL https://downloads.mariadb.com/Connectors/java/connector-java-3.3.2/mariadb-java-client-3.3.2.jar \
      -o ${SPARK_HOME}/jars/mariadb-java-client.jar

# PySpark + Delta
# delta-spark 3.2.0, not 3.3.1, due to compatibility issues
ENV VIRTUAL_ENV=/opt/venv
RUN python3.12 -m venv "$VIRTUAL_ENV" \
    && "$VIRTUAL_ENV/bin/pip" install --upgrade pip \
    && "$VIRTUAL_ENV/bin/pip" install --no-cache-dir \
       pyspark==${SPARK_VERSION} \
       delta-spark==3.2.0 \
       azure-core==1.31.0 \
       azure-storage-blob==12.23.0 \
       azure-storage-file-datalake==12.17.0
ENV PATH="$VIRTUAL_ENV/bin:$PATH" \
    PYSPARK_PYTHON=python \
    PYSPARK_DRIVER_PYTHON=python

# Verify installations
RUN java -version \
    && scala -version \
    && python3.12 --version \
    && R --version \
    && ${SPARK_HOME}/bin/spark-submit --version

CMD ["/bin/bash"]
